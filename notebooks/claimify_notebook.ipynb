{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77902bd",
   "metadata": {},
   "source": [
    "# 💬 Claimify reproduction study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1663efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8540b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chat import load_md_prompts\n",
    "\n",
    "PROMPT_TEMPLATES = load_md_prompts(\"claimify\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00643476",
   "metadata": {},
   "source": [
    "## 1. Input Question and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "064c8039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting charboundary[numpy,onnx]\n",
      "  Downloading charboundary-0.5.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from charboundary[numpy,onnx]) (1.7.1)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from charboundary[numpy,onnx]) (4.67.1)\n",
      "Collecting skops>=0.9.0 (from charboundary[numpy,onnx])\n",
      "  Downloading skops-0.13.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from charboundary[numpy,onnx]) (1.26.4)\n",
      "Collecting onnx>=1.15.0 (from charboundary[numpy,onnx])\n",
      "  Downloading onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting skl2onnx>=1.16.0 (from charboundary[numpy,onnx])\n",
      "  Downloading skl2onnx-1.19.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting onnxruntime>=1.16.0 (from charboundary[numpy,onnx])\n",
      "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from onnx>=1.15.0->charboundary[numpy,onnx]) (6.31.1)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from onnx>=1.15.0->charboundary[numpy,onnx]) (4.14.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.16.0->charboundary[numpy,onnx])\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.16.0->charboundary[numpy,onnx])\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from onnxruntime>=1.16.0->charboundary[numpy,onnx]) (25.0)\n",
      "Requirement already satisfied: sympy in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from onnxruntime>=1.16.0->charboundary[numpy,onnx]) (1.14.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from scikit-learn>=1.3.0->charboundary[numpy,onnx]) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from scikit-learn>=1.3.0->charboundary[numpy,onnx]) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from scikit-learn>=1.3.0->charboundary[numpy,onnx]) (3.6.0)\n",
      "Collecting prettytable>=3.9 (from skops>=0.9.0->charboundary[numpy,onnx])\n",
      "  Downloading prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: wcwidth in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from prettytable>=3.9->skops>=0.9.0->charboundary[numpy,onnx]) (0.2.13)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16.0->charboundary[numpy,onnx])\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/personal/ullriher/venvs/aug25/lib/python3.12/site-packages (from sympy->onnxruntime>=1.16.0->charboundary[numpy,onnx]) (1.3.0)\n",
      "Downloading charboundary-0.5.0-py3-none-any.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading skl2onnx-1.19.1-py3-none-any.whl (315 kB)\n",
      "Downloading skops-0.13.0-py3-none-any.whl (131 kB)\n",
      "Downloading prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, prettytable, onnx, humanfriendly, coloredlogs, skops, skl2onnx, onnxruntime, charboundary\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [charboundary]m━━━━\u001b[0m \u001b[32m8/9\u001b[0m [charboundary]\n",
      "\u001b[1A\u001b[2KSuccessfully installed charboundary-0.5.0 coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 onnx-1.18.0 onnxruntime-1.22.1 prettytable-3.16.0 skl2onnx-1.19.1 skops-0.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install charboundary[numpy,onnx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e39540ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sentence: \\n<>\\n\\n4-step stream of consciousness thought process (1. reflect on criteria at a high-level -> 2. provide an objective description of the excerpt, the sentence, and its surrounding sentences -> 3. consider all possible perspectives on whether the sentence explicitly or implicitly contains a specific and verifiable proposition, or if it just contains an introduction for the following \\nsentence(s), a conclusion for the preceding sentence(s), broad or generic statements, opinions, interpretations, speculations, statements about a lack of information, etc. -> 4. only if it contains a specific and verifiable proposition: reflect on whether any changes are needed to ensure that the entire sentence only contains verifiable information):\\n1) A sentence must assert at least one checkable claim to qualify; absence of content cannot contain a proposition. 2) The provided \"Sentence\" field is empty, and no surrounding context is given. 3) An empty sentence cannot explicitly or implicitly contain a specific, verifiable proposition; it conveys no claim. 4) Not applicable since there is no proposition to rewrite.\\n\\nFinal submission:\\nDoes NOT contain a specific and verifiable proposition\\n\\nSentence with only verifiable information:\\nNone', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 825, 'prompt_tokens': 1224, 'total_tokens': 2049, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-C2wxkSiTsyBCSlIznfsM2Zuri5mGk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bfafa05e-0673-45d1-93bf-c9850796e485-0', usage_metadata={'input_tokens': 1224, 'output_tokens': 825, 'total_tokens': 2049, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic chatprompttemplate llm chat with gpt-5 using 'selection' prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "import ssl\n",
    "import certifi\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-5\")\n",
    "excerpt = \"\"\"\"\"\"\n",
    "question = \"\"\"\"\"\"\n",
    "sentence = \"\"\"\"\"\"\n",
    "chat.invoke(PROMPT_TEMPLATES[\"selection\"].format_messages(excerpt=excerpt, question=question, sentence=sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.claimify import SelectionResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187c801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOllama(model=\"qwen3:14b\")\n",
    "output = chat.invoke(PROMPT_TEMPLATES[\"selection\"].format_messages(excerpt=\"todo\", question=\"todo\", sentence=\"todo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa520fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, let\\'s tackle this problem step by step. The user wants me to determine if a given sentence from a response contains a specific and verifiable proposition based on the provided rules.\\n\\nFirst, I need to recall the criteria. A specific and verifiable proposition is something that can be checked for truth, like a fact. The rules mention that if the sentence is about a lack of information, it doesn\\'t count. Also, it doesn\\'t matter if the proposition is true or false, just whether it\\'s specific and verifiable. Ambiguous terms are okay as long as the fact-checker can resolve them.\\n\\nNow, looking at the example given in the problem statement. The user provided a scenario where the sentence is \"John\" following the question \"Who is the CEO of Company X?\" and the preceding sentence. The answer here is that \"John\" contains a specific proposition because it directly answers the question with a name, which can be verified.\\n\\nAnother example is when the preceding sentence mentions Jane Doe introducing a concept, and the sentence says \"It means using technology to restore ecosystems.\" That\\'s specific because it defines the concept mentioned earlier.\\n\\nBut if the sentence is a conclusion summarizing topics covered, even if they are detailed before, it\\'s considered a conclusion and not a specific proposition.\\n\\nNow, the user\\'s input is \"todo\" for all parts. But since the user hasn\\'t provided the actual question, excerpt, or sentence, I need to consider that maybe this is a placeholder. However, the user might have intended to test the system\\'s ability to process the rules even without specific data. But in reality, the assistant should process the given input. However, since the input is all \"todo,\" perhaps the user is testing the system\\'s ability to handle incomplete data, but according to the problem\\'s setup, the user should have provided the necessary information.\\n\\nWait, the user\\'s message is the initial instruction, and the actual query is not provided. But in the problem setup, the user is supposed to input a question, an excerpt, and a sentence. However, in this case, the user might have left it as \"todo\" as a placeholder. But given the instructions, I need to process the example given in the problem statement, not the user\\'s input. Wait, no, the user is providing the problem as the input, and the assistant is to process that.\\n\\nWait, looking back at the user\\'s message, the user provided the initial instruction, then in the \"Question\" section, \"todo\", then \"Excerpt: todo\", and \"Sentence: todo\". So the user hasn\\'t actually provided the necessary information. But in the context of the problem, perhaps this is a test case where the assistant is supposed to handle a scenario where the information is missing. However, according to the rules, the assistant should process the given question, excerpt, and sentence. But since they\\'re all \"todo\", perhaps the assistant is supposed to return that the information is missing. However, in the original problem statement, the user provided an example with specific data, but in this case, the user\\'s input is incomplete.\\n\\nThis is a bit confusing. However, considering that the user might have intended to provide a test case with the example from the problem statement, but in the current setup, the user input is all \"todo\". Therefore, the assistant might need to respond that the information is incomplete, but according to the rules, the assistant should process the given data. However, since the data is missing, perhaps the correct response is that the sentence cannot be evaluated due to missing information. But according to the rules, the assistant is to determine based on the given information. However, without the actual question, excerpt, and sentence, it\\'s impossible to proceed. Therefore, the answer would be that the sentence is not provided, and thus cannot be evaluated. But the user might have made a mistake in the input.\\n\\nAlternatively, perhaps this is a test to see if the assistant can handle such scenarios. But according to the initial instructions, the assistant is to process the given question, excerpt, and sentence. Since they\\'re all \"todo\", the assistant cannot proceed. However, in the problem statement\\'s example, the user provided a specific question, excerpt, and sentence. Therefore, perhaps the user intended to provide that as the input but mistakenly used \"todo\". But in this case, the user\\'s input is incomplete. Therefore, the assistant should inform that the input is incomplete. However, the user hasn\\'t provided any actual data to work with, so the assistant can\\'t process it. Therefore, the answer would be that the information is missing, and thus, the assistant can\\'t determine if the sentence contains a specific proposition.\\n</think>\\n\\nSentence: \\n<insert> \\n\\n4-step stream of consciousness thought process (1. reflect on criteria at a high-level -> 2. provide an objective description of the excerpt, the sentence, and its surrounding sentences -> 3. consider all possible perspectives on whether the sentence explicitly or implicitly contains a specific and verifiable proposition, or if it just contains an introduction for the following \\nsentence(s), a conclusion for the preceding sentence(s), broad or generic statements, opinions, interpretations, speculations, statements about a lack of information, etc. -> 4. only if it contains a specific and verifiable proposition: reflect on whether any changes are needed to ensure that the entire sentence only contains verifiable information):\\n<insert> \\n\\nFinal submission:\\n<insert \\'Contains a specific and verifiable proposition\\' or \\'Does NOT contain a specific and verifiable proposition\\'>\\n\\nSentence with only verifiable information:\\n<insert changed sentence, or \\'remains unchanged\\' if no changes, or \\'None\\' if the sentence does NOT contain a specific and verifiable proposition>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7453925e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['List The Wall Street Journal předtím uvedl, že Evropané na schůzi představili vlastní plán jednání o ukončení války.',\n",
       " 'Podle dokumentu před přiznáním jakýchkoli ústupků Rusku je nutné vyhlásit příměří.',\n",
       " 'Eventuální územní ústupky musí být reciproční, musí je tedy udělat Ukrajina i Rusko.',\n",
       " 'Plán také žádá silné bezpečnostní záruky pro Ukrajinu včetně členství v NATO.',\n",
       " 'Trump v minulosti dával najevo, že takový postup si nepřeje.',\n",
       " 'Bílý dům zvažuje pozvání Zelenského na Aljašku',\n",
       " 'V pátek 15. srpna se Trump sejde na Aljašce se svým ruským protějškem Vladimirem Putinem.',\n",
       " 'Půjde o dvoustrannou schůzku, Bílý dům však podle informací stanice NBC News stále zvažuje, že na Aljašku pozve také ukrajinského prezidenta Volodymyra Zelenského.',\n",
       " 'NBC News se odvolává na vysoce postaveného amerického činitele a tři osoby, které byly o interních diskusích v Bílém domě informovány.',\n",
       " '„Diskutuje se o tom,“ citovala stanice jednoho z lidí seznámeného s obsahem jednání.',\n",
       " 'Vysoce postavený americký činitel a lidé obeznámení s rozhovory zároveň uvedli, že návštěva Zelenského zatím nebyla s konečnou platností dohodnuta a není jasné, zda se Zelenskyj nakonec jednání na Aljašce zúčastní.',\n",
       " 'Lipavský o schůzce Trumpa s Putinem: Hranice Ukrajiny neposune vydírání',\n",
       " 'Vysoce postavený představitel Trumpovy administrativy k tomu řekl, že je to „rozhodně“ možné.',\n",
       " '„Všichni silně doufají, že k tomu dojde,“ dodal.',\n",
       " 'Trump podle něj zůstává otevřen možnosti trojstranného summitu s oběma lídry.',\n",
       " 'Momentálně se ale Bílý dům „soustředí na přípravu bilaterální schůzky, o kterou požádal prezident Putin“, řekl činitel.',\n",
       " 'Ukrajinský prezident Volodymyr Zelenskyj v sobotu varoval, že jakékoliv řešení rusko-ukrajinského konfliktu učiněné bez účasti Ukrajiny bude řešením proti míru.',\n",
       " 'Dodal, že Ukrajinci nevydají svou zemi okupantům.',\n",
       " 'Šéf Kremlu tento týden prohlásil, že není proti setkání se Zelenským, ale pro takovou schůzku podle něj ještě nejsou podmínky.',\n",
       " 'Zelenskyj opakovaně vyzval k osobnímu jednání mezi ním a Putinem s cílem ukončit ruskou invazi na Ukrajinu.',\n",
       " 'Ukrajina se brání rozsáhlé ruské vojenské agresi od února 2022.',\n",
       " 'Zatím není jasné, jestli je Moskva připravena vzdát se jakéhokoliv území, které nyní okupuje.',\n",
       " 'Kyjev dosud podle agentury Bloomberg dával najevo, že ruskou okupaci a anexi svého území nepřijme.',\n",
       " 'Podle agentury Reuters sice Ukrajina signalizovala flexibilitu při hledání cest k ukončení války, ale přijmout ztrátu zhruba pětiny území by bylo velmi bolestivé a politicky složité pro Zelenského a jeho vládu.',\n",
       " ')',\n",
       " 'Zdroj: https://www.idnes.cz/zpravy/zahranicni/zelensky-trump-putin-aljaska-schuzka-usa-rusko-ukrajina-valka.A250810_071424_zahranicni_svm']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import nltk\n",
    "\n",
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits a block of text into sentences, handling paragraphs and lists.\n",
    "    This replicates the methodology from Appendix C.1 of the Claimify paper.\n",
    "    \n",
    "    Args:\n",
    "        text: The input text to split\n",
    "        \n",
    "    Returns:\n",
    "        A list of sentence strings\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = []\n",
    "    # First, split by newlines to handle paragraphs and list items\n",
    "    paragraphs = text.split('\\n')\n",
    "    for para in paragraphs:\n",
    "        if para.strip():  # Avoid empty paragraphs\n",
    "            # Then, use NLTK's sentence tokenizer on each paragraph\n",
    "            sentences.extend(nltk.sent_tokenize(para))\n",
    "    return sentences\n",
    "\n",
    "split_into_sentences(\"\"\"\n",
    "List The Wall Street Journal předtím uvedl, že Evropané na schůzi představili vlastní plán jednání o ukončení války. Podle dokumentu před přiznáním jakýchkoli ústupků Rusku je nutné vyhlásit příměří. Eventuální územní ústupky musí být reciproční, musí je tedy udělat Ukrajina i Rusko. Plán také žádá silné bezpečnostní záruky pro Ukrajinu včetně členství v NATO. Trump v minulosti dával najevo, že takový postup si nepřeje.\n",
    "\n",
    "Bílý dům zvažuje pozvání Zelenského na Aljašku\n",
    "V pátek 15. srpna se Trump sejde na Aljašce se svým ruským protějškem Vladimirem Putinem. Půjde o dvoustrannou schůzku, Bílý dům však podle informací stanice NBC News stále zvažuje, že na Aljašku pozve také ukrajinského prezidenta Volodymyra Zelenského.\n",
    "\n",
    "NBC News se odvolává na vysoce postaveného amerického činitele a tři osoby, které byly o interních diskusích v Bílém domě informovány.\n",
    "\n",
    "„Diskutuje se o tom,“ citovala stanice jednoho z lidí seznámeného s obsahem jednání. Vysoce postavený americký činitel a lidé obeznámení s rozhovory zároveň uvedli, že návštěva Zelenského zatím nebyla s konečnou platností dohodnuta a není jasné, zda se Zelenskyj nakonec jednání na Aljašce zúčastní.\n",
    "\n",
    "Lipavský o schůzce Trumpa s Putinem: Hranice Ukrajiny neposune vydírání\n",
    "\n",
    "Vysoce postavený představitel Trumpovy administrativy k tomu řekl, že je to „rozhodně“ možné. „Všichni silně doufají, že k tomu dojde,“ dodal.\n",
    "\n",
    "Trump podle něj zůstává otevřen možnosti trojstranného summitu s oběma lídry. Momentálně se ale Bílý dům „soustředí na přípravu bilaterální schůzky, o kterou požádal prezident Putin“, řekl činitel.\n",
    "\n",
    "Ukrajinský prezident Volodymyr Zelenskyj v sobotu varoval, že jakékoliv řešení rusko-ukrajinského konfliktu učiněné bez účasti Ukrajiny bude řešením proti míru. Dodal, že Ukrajinci nevydají svou zemi okupantům.\n",
    "\n",
    "Šéf Kremlu tento týden prohlásil, že není proti setkání se Zelenským, ale pro takovou schůzku podle něj ještě nejsou podmínky. Zelenskyj opakovaně vyzval k osobnímu jednání mezi ním a Putinem s cílem ukončit ruskou invazi na Ukrajinu.\n",
    "\n",
    "Ukrajina se brání rozsáhlé ruské vojenské agresi od února 2022. Zatím není jasné, jestli je Moskva připravena vzdát se jakéhokoliv území, které nyní okupuje. Kyjev dosud podle agentury Bloomberg dával najevo, že ruskou okupaci a anexi svého území nepřijme.\n",
    "\n",
    "Podle agentury Reuters sice Ukrajina signalizovala flexibilitu při hledání cest k ukončení války, ale přijmout ztrátu zhruba pětiny území by bylo velmi bolestivé a politicky složité pro Zelenského a jeho vládu.\n",
    ")\n",
    "Zdroj: https://www.idnes.cz/zpravy/zahranicni/zelensky-trump-putin-aljaska-schuzka-usa-rusko-ukrajina-valka.A250810_071424_zahranicni_svm\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f31e976d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 12:38:06,040 - claimify.pipeline - INFO - Structured outputs enabled for improved reliability\n"
     ]
    }
   ],
   "source": [
    "from utils.claimify import ClaimifyPipeline\n",
    "from utils.chat import chat_factory\n",
    "\n",
    "pipeline = ClaimifyPipeline(chat_factory(\"gpt-5-mini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80236d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"Mír bez Ukrajiny nepůjde, zdůrazňuje Evropa. Zelenskyj by mohl na Aljašku\n",
    "Cestu k míru na Ukrajině nelze určit bez Ukrajiny, uvedli ve společném prohlášení lídři Británie, Finska, Francie, Itálie, Německa a Polska a předsedkyně Evropské komise Ursula von der Leyenová. Bílý dům zvažuje, že pozve ukrajinského prezidenta Volodymyra Zelenského na Aljašku, kde se má americký prezident Donald Trump 15. srpna sejít se svým ruským protějškem Vladimirem Putinem.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4613bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cau\n"
     ]
    }
   ],
   "source": [
    "print(\"cau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d8432a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 12:38:43,571 - claimify.pipeline - INFO - Processing 4 sentences\n",
      "2025-08-10 12:38:43,571 - claimify.pipeline - INFO - Processing sentence 1/4: Mír bez Ukrajiny nepůjde, zdůrazňuje Evropa....\n",
      "2025-08-10 12:38:52,805 - claimify.pipeline - INFO - SELECTION: Sentence verifiable\n",
      "2025-08-10 12:39:07,959 - claimify.pipeline - INFO - DISAMBIGUATION: Sentence resolved\n",
      "2025-08-10 12:39:27,134 - claimify.pipeline - INFO - DECOMPOSITION: Extracted 3 claims\n",
      "2025-08-10 12:39:27,134 - claimify.pipeline - INFO - Processing sentence 2/4: Zelenskyj by mohl na Aljašku...\n",
      "2025-08-10 12:39:39,491 - claimify.pipeline - INFO - SELECTION: Sentence verifiable\n",
      "2025-08-10 12:39:53,742 - claimify.pipeline - INFO - DISAMBIGUATION: Sentence resolved\n",
      "2025-08-10 12:40:09,230 - claimify.pipeline - INFO - DECOMPOSITION: Extracted 2 claims\n",
      "2025-08-10 12:40:09,230 - claimify.pipeline - INFO - Processing sentence 3/4: Cestu k míru na Ukrajině nelze určit bez Ukrajiny, uvedli ve společném prohlášení lídři Británie, Fi...\n",
      "2025-08-10 12:40:20,020 - claimify.pipeline - INFO - SELECTION: Sentence verifiable\n",
      "2025-08-10 12:40:36,065 - claimify.pipeline - INFO - DISAMBIGUATION: Sentence resolved\n",
      "2025-08-10 12:40:58,937 - claimify.pipeline - INFO - DECOMPOSITION: Extracted 8 claims\n",
      "2025-08-10 12:40:58,938 - claimify.pipeline - INFO - Processing sentence 4/4: Bílý dům zvažuje, že pozve ukrajinského prezidenta Volodymyra Zelenského na Aljašku, kde se má ameri...\n",
      "2025-08-10 12:41:07,404 - claimify.pipeline - INFO - SELECTION: Sentence verifiable\n",
      "2025-08-10 12:41:20,320 - claimify.pipeline - INFO - DISAMBIGUATION: Sentence unresolvable\n",
      "2025-08-10 12:41:20,320 - claimify.pipeline - INFO - Pipeline completed: 13 unique claims extracted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The leaders of Britain, Finland, France, Italy, Germany, and Poland and European Commission President Ursula von der Leyen issued a joint statement - true or false?',\n",
       " 'In that joint statement, those leaders and Ursula von der Leyen said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?',\n",
       " 'Ursula von der Leyen is the President of the European Commission - true or false?',\n",
       " 'Volodymyr Zelenskyj is the President of Ukraine. - true or false?',\n",
       " 'Volodymyr Zelenskyj might travel to Alaska [based on a report stating that the White House is considering inviting him to Alaska where US President Donald Trump is scheduled to meet Russian President Vladimir Putin on August 15] - true or false?',\n",
       " 'The leaders of Britain [as part of a joint statement issued by the leaders of Britain, Finland, France, Italy, Germany, Poland, and European Commission President Ursula von der Leyen] said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?',\n",
       " 'The leaders of Finland [as part of a joint statement issued by the leaders of Britain, Finland, France, Italy, Germany, Poland, and European Commission President Ursula von der Leyen] said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?',\n",
       " 'The leaders of France [as part of a joint statement issued by the leaders of Britain, Finland, France, Italy, Germany, Poland, and European Commission President Ursula von der Leyen] said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?',\n",
       " 'The leaders of Italy [as part of a joint statement issued by the leaders of Britain, Finland, France, Italy, Germany, Poland, and European Commission President Ursula von der Leyen] said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?',\n",
       " 'The leaders of Germany [as part of a joint statement issued by the leaders of Britain, Finland, France, Italy, Germany, Poland, and European Commission President Ursula von der Leyen] said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?',\n",
       " 'The leaders of Poland [as part of a joint statement issued by the leaders of Britain, Finland, France, Italy, Germany, Poland, and European Commission President Ursula von der Leyen] said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?',\n",
       " 'European Commission President Ursula von der Leyen [as part of a joint statement issued by the leaders of Britain, Finland, France, Italy, Germany, Poland, and the European Commission President] said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?',\n",
       " 'A joint statement by the leaders of Britain, Finland, France, Italy, Germany, and Poland and by European Commission President Ursula von der Leyen said that the path to peace in Ukraine cannot be determined without Ukraine - true or false?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipeline.run(article)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a561897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an assistant to a fact-checker. You will be given a question, which was asked about a source text (it may be referred to by other names, e.g., a disa\\ndataset). You will also be given an excerpt from a response to the question. If it contains \"[...]\", this means that you are NOT seeing all sentences in the response. You will also be given a particular sentence from the response. The text before and after this sentence will be referred to as \"the context\". Your task is to \"decontextualize\" the sentence, which means:\\n1. determine whether it\\'s possible to resolve partial names and undefined acronyms/abbreviations in the sentence using the question and the context; if it is possible, you will make the necessary changes to the sentence\\n2. determine whether the sentence in isolation contains linguistic ambiguity that has a clear resolution using the question and the context; if it does, you will make the necessary changes to the sentence\\n\\nNote the following rules:\\n- \"Linguistic ambiguity\" refers to the presence of multiple possible meanings in a sentence. Vagueness and generality are NOT linguistic ambiguity. Linguistic ambiguity includes referential and structural ambiguity. Temporal ambiguity is a type of referential ambiguity.\\n- If it is unclear whether the sentence is directly answering the question, you should NOT count this as linguistic ambiguity. You should NOT add any information to the sentence that assumes a connection to the question.\\n- If a name is only partially given in the sentence, but the full name is provided in the question or the context, the DecontextualizedSentence must always use the full name. The same rule applies to definitions for acronyms and abbreviations. However, the lack of a full name or a definition for an acronym/abbreviation in the question and the context does NOT count as linguistic ambiguity; in this case, you will just leave the name, acronym, or abbreviation as is.\\n- Do NOT include any citations in the DecontextualizedSentence.\\n- Do NOT use any external knowledge beyond what is stated in the question, context, and sentence.\\n\\nHere are some correct examples that you should pay attention to:\\n1. Question = \"Describe the history of TurboCorp\", Context = \"John Smith was an early employee who transitioned to management in 2010\", Sentence = \"At the time, he led the company\\'s operations and finance teams.\"\\n    - For referential ambiguity, \"At the time\", \"he\", and \"the company\\'s\" are unclear. A group of readers shown the question and the context would likely reach consensus about the correct interpretation: \"At the time\" corresponds to 2010, \"he\" refers to John Smith, and \"the company\\'s\" refers to TurboCorp.\\n    - DecontextualizedSentence: In 2010, John Smith led TurboCorp\\'s operations and finance teams.\\n2. Question = \"Who are notable executive figures?\", Context = \"[...]**Jane Doe**\", Sentence = \"These notes indicate that her leadership at TurboCorp and MiniMax is accelerating progress in renewable energy and sustainable \\nagriculture.\"\\n    - For referential ambiguity, \"these notes\" and \"her\" are unclear. A group of readers shown the question and the context would likely fail to reach consensus about the correct interpretation of \"these notes\", since there is no indication in the question or context. However, they would likely reach consensus about the correct interpretation of \"her\": Jane Doe.\\n    - For structural ambiguity, the sentence could be interpreted as: (1) Jane\\'s leadership is accelerating progress in renewable energy and sustainable agriculture at both TurboCorp and MiniMax, (2) Jane\\'s leadership is accelerating progress in renewable energy at TurboCorp and in sustainable agriculture at MiniMax. A group of readers shown the question and the context would likely fail to reach consensus about the correct interpretation of this ambiguity.\\n    - DecontextualizedSentence: Cannot be decontextualized\\n3. Question = \"Who founded MiniMax?\", Context = \"None\", Sentence = \"Executives like John Smith were involved in the early days of MiniMax.\"\\n    - For referential ambiguity, \"like John Smith\" is unclear. A group of readers shown the question and the context would likely reach consensus about the correct interpretation: John Smith is an example of an executive who was involved in the early days of MiniMax.\\n    - Note that \"Involved in\" and \"the early days\" are vague, but they are NOT linguistic ambiguity.\\n    - DecontextualizedSentence: John Smith is an example of an executive who was involved in the early days of MiniMax.\\n4. Question = \"What advice is given to young entrepreneurs?\", Context = \\n\"# Ethical Considerations\", Sentence = \"Sustainable manufacturing, as emphasized by John Smith and Jane Doe, is critical for customer buy-in and long-term success.\"\\n    - For structural ambiguity, the sentence could be interpreted as: (1) John Smith and Jane Doe emphasized that sustainable manufacturing is critical for customer buy-in and long-term success, (2) John Smith and Jane Doe emphasized sustainable manufacturing while the claim that sustainable manufacturing is critical for customer buy-in and long-term success is attributable to the writer, not to John Smith and Jane Doe. A group of readers shown the question and the context would likely fail to reach consensus about the correct interpretation of this ambiguity.\\n    - DecontextualizedSentence: Cannot be decontextualized\\n5. Question = \"What are common strategies for building successful teams?\", Context = \"One of the most common strategies is creating a diverse team.\", Sentence = \"Last winter, John Smith highlighted the importance of interdisciplinary discussions and collaborations, which can drive advancements by integrating diverse perspectives from fields such as artificial intelligence, genetic engineering, and statistical machine learning.\"\\n    - For referential ambiguity, \"Last winter\" is unclear. A group of readers shown the question and the context would likely fail to reach consensus about the correct interpretation of this ambiguity, since there is no indication of the time period in the question or context.\\n    - For structural ambiguity, the sentence could be interpreted as: (1) John Smith highlighted the importance of interdisciplinary discussions and collaborations and that they can drive advancements by integrating diverse perspectives from some example fields, (2) John Smith only highlighted the importance of interdisciplinary discussions and collaborations while the claim that they can drive advancements by integrating diverse perspectives from some example fields is attributable to the writer, not to John Smith. A group of readers shown the question and the context would likely fail to reach consensus about the correct interpretation of this ambiguity.\\n    - DecontextualizedSentence: Cannot be decontextualized\\n6. Question = \"What opinions are provided on disruptive technologies?\", Context = \"[...]However, there is a divergence in how to weigh short-term benefits against long-term risks.\", Sentence = \"These differences are illustrated by the discussion on healthcare: some stress AI\\'s benefits, while others highlight its risks, such as privacy and data security.\"\\n    - For referential ambiguity, \"These differences\" is unclear. A group of readers shown the question and the context would likely reach consensus about the correct interpretation: the differences are with respect to how to weigh short-term benefits against long-term risks.\\n    - For structural ambiguity, the sentence could be interpreted as: (1) privacy and data security are examples of risks, (2) privacy and data security are examples of both benefits and risks. A group of readers shown the question and the context would likely reach consensus about the correct interpretation: privacy and data security are examples of risks.\\n    - Note that \"Some\" and \"others\" are vague, but they are not linguistic ambiguity.\\n    - DecontextualizedSentence: The differences in how to weigh short-term benefits against long-term risks are illustrated by the discussion on healthcare. Some experts stress AI\\'s benefits with respect to healthcare. Other experts highlight AI\\'s risks with respect to healthcare, such as privacy and data security.\\n\\nFirst, print \"Incomplete Names, Acronyms, Abbreviations:\" followed by your step-by-step reasoning for determining whether the Sentence contains any partial names and undefined acronyms/abbreviations. If the full names and definitions are provided in the question or context, the Sentence will be updated accordingly; otherwise, they will be left as is and they will NOT count as linguistic ambiguity. Next, print \"Linguistic Ambiguity in \\'<insert the \\nsentence>\\':\" followed by your step-by-step reasoning for checking (1) referential and (2) structural ambiguity (and note that 1. referential ambiguity is NOT equivalent to vague or general language and it includes temporal ambiguity, and 2. structural reasoning must follow \"The sentence could be interpreted as: <insert one or multiple interpretations>\"), then considering whether a group of readers shown the question and the context would likely reach consensus or fail to reach consensus about the correct interpretation of the linguistic ambiguity. If they would likely fail to reach consensus, print\\n\"DecontextualizedSentence: Cannot be decontextualized\"; otherwise, first print\\n\"Changes Needed to Decontextualize the Sentence:\" followed by a list of all changes needed to ensure the Sentence is fully decontextualized (e.g., replace \\n\"executives like John Smith\" with \"John Smith is an example of an executive who\") and includes all full names and definitions for acronyms/abbreviations (only if they were provided in the question and the context), then print \\n\"DecontextualizedSentence:\" followed by the final sentence (or collection of sentences) that implements all changes.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Question:\\n\\n\\nExcerpt:\\n\\n\\nSentence:\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.chat import get_prompt\n",
    "prompt = get_prompt(\"claimify\", \"disambiguation\", {\"question\": question, \"excerpt\": excerpt, \"sentence\": sentence})\n",
    "# type of prompt\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d377ea65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an assistant to a fact-checker. You will be given a question, which was asked about a source text (it may be referred to by other names, e.g., a \\ndataset). You will also be given an excerpt from a response to the question. If it contains \"[...]\", this means that you are NOT seeing all sentences in the response. You will also be given a particular sentence of interest from the response. Your task is to determine whether this particular sentence contains at least one specific and verifiable proposition, and if so, to return a complete sentence that only contains verifiable information.   \\n\\nNote the following rules:\\n- If the sentence is about a lack of information, e.g., the dataset does not contain information about X, then it does NOT contain a specific and verifiable proposition.\\n- It does NOT matter whether the proposition is true or false.\\n- It does NOT matter whether the proposition is relevant to the question.\\n- It does NOT matter whether the proposition contains ambiguous terms, e.g., a pronoun without a clear antecedent. Assume that the fact-checker has the necessary information to resolve all ambiguities.\\n- You will NOT consider whether a sentence contains a citation when determining if it has a specific and verifiable proposition.\\n\\nYou must consider the preceding and following sentences when determining if the sentence has a specific and verifiable proposition. For example:\\n- if preceding sentence = \"Who is the CEO of Company X?\" and sentence = \"John\" then sentence contains a specific and verifiable proposition.\\n- if preceding sentence = \"Jane Doe introduces the concept of regenerative technology\" and sentence = \"It means using technology to restore ecosystems\" then sentence contains a specific and verifiable proposition.\\n- if preceding sentence = \"Jane is the President of Company Y\" and sentence = \"She has increased its revenue by 20\\\\%\" then sentence contains a specific and verifiable proposition.\\n- if sentence = \"Guests interviewed on the podcast suggest several strategies for fostering innovation\" and the following sentences expand on this point \\n(e.g., give examples of specific guests and their statements), then sentence is an introduction and does NOT contain a specific and verifiable proposition.\\n- if sentence = \"In summary, a wide range of topics, including new technologies, personal development, and mentorship are covered in the dataset\" and the preceding sentences provide details on these topics, then sentence is a conclusion and does NOT contain a specific and verifiable proposition.\\n\\nHere are some examples of sentences that do NOT contain any specific and verifiable propositions:\\n- By prioritizing ethical considerations, companies can ensure that their innovations are not only groundbreaking but also socially responsible\\n- Technological progress should be inclusive\\n- Leveraging advanced technologies is essential for maximizing productivity\\n- Networking events can be crucial in shaping the paths of young entrepreneurs and providing them with valuable connections\\n- AI could lead to advancements in healthcare\\n- This implies that John Smith is a courageous person\\n\\nHere are some examples of sentences that likely contain a specific and verifiable proposition and how they can be rewritten to only include verifiable information:\\n- The partnership between Company X and Company Y illustrates the power of innovation -> \"There is a partnership between Company X and Company Y\"\\n- Jane Doe\\'s approach of embracing adaptability and prioritizing customer feedback can be valuable advice for new executives -> \"Jane Doe\\'s approach includes embracing adaptability and prioritizing customer feedback\"\\n- Smith\\'s advocacy for renewable energy is crucial in addressing these challenges -> \"Smith advocates for renewable energy\"\\n- **John Smith**: instrumental in numerous renewable energy initiatives, playing a pivotal role in Project Green -> \"John Smith participated in renewable energy initiatives, playing a role in Project Green\"\\n- The technology is discussed for its potential to help fight climate change -> remains unchanged\\n- John, the CEO of Company X, is a notable example of effective leadership -> \\n\"John is the CEO of Company X\"\\n- Jane emphasizes the importance of collaboration and perseverance -> remains unchanged\\n- The Behind the Tech podcast by Kevin Scott is an insightful podcast that explores the themes of innovation and technology -> \"The Behind the Tech podcast by Kevin Scott is a podcast that explores the themes of innovation and technology\"\\n- Some economists anticipate the new regulation will immediately double production costs, while others predict a gradual increase -> remains unchanged\\n- AI is frequently discussed in the context of its limitations in ethics and privacy -> \"AI is discussed in the context of its limitations in ethics and privacy\"\\n- The power of branding is highlighted in discussions featuring John Smith and Jane Doe -> remains unchanged\\n- Therefore, leveraging industry events, as demonstrated by Jane\\'s experience at the Tech Networking Club, can provide visibility and traction for new ventures -> \"Jane had an experience at the Tech Networking Club, and her experience involved leveraging an industry event to provide visibility and traction for a new venture\"\\n\\nYour output must adhere to the following format exactly. Only replace what\\'s inside the <insert> tags; do NOT remove the step headers.  \\nSentence: \\n<insert> \\n\\n4-step stream of consciousness thought process (1. reflect on criteria at a high-level -> 2. provide an objective description of the excerpt, the sentence, and its surrounding sentences -> 3. consider all possible perspectives on whether the sentence explicitly or implicitly contains a specific and verifiable proposition, or if it just contains an introduction for the following \\nsentence(s), a conclusion for the preceding sentence(s), broad or generic statements, opinions, interpretations, speculations, statements about a lack of information, etc. -> 4. only if it contains a specific and verifiable proposition: reflect on whether any changes are needed to ensure that the entire sentence only contains verifiable information):\\n<insert>\\n\\nFinal submission:\\n<insert \\'Contains a specific and verifiable proposition\\' or \\'Does NOT contain a specific and verifiable proposition\\'>\\n\\nSentence with only verifiable information:\\n<insert changed sentence, or \\'remains unchanged\\' if no changes, or \\'None\\' if the sentence does NOT contain a specific and verifiable proposition>', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Question:\\n\\n\\nExcerpt:\\n\\n\\nSentence:\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prompt(\"claimify\", \"selection\", {\"question\": question, \"excerpt\": excerpt, \"sentence\": sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07aa798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
